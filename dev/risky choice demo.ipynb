{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of risky choice tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Python to the path where we have installed the bad and darc packages\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/btvincent/git-local/darc-experiments-python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import darc\n",
    "from darc.delayed import models\n",
    "from darc.designs import BayesianAdaptiveDesignGeneratorDARC\n",
    "from darc.risky.designs import Griskevicius2011, DuGreenMyerson2002\n",
    "from dev.darc_parameter_recovery import parameter_recovery_sweep, simulated_experiment_trial_loop\n",
    "from darc.data_plotting import plot_delay_without_front_end_delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generating process\n",
    "Define everything related to the true simulated observer which generates the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~ UPDATE THIS FOR RISKY CHOICE ~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "data_generating_model = models.Hyperbolic\n",
    "\n",
    "def hyperbolic_discount_func(delay, logk):\n",
    "    k = np.exp(logk)\n",
    "    return np.divide(1, (1 + k * delay))\n",
    "\n",
    "def hyperbolic_posterior_predictive(ax, fitted_model, max_delay):\n",
    "    logk = fitted_model.θ['logk'].values  # get posterior samples\n",
    "    delays = np.linspace(0, max_delay, 500)\n",
    "    logk_percentiles = np.percentile(logk,[2.5, 50, 100-2.5])    \n",
    "    \n",
    "    y_upper = hyperbolic_discount_func(delays, logk_percentiles[2])\n",
    "    y_median = hyperbolic_discount_func(delays, logk_percentiles[1])\n",
    "    y_lower = hyperbolic_discount_func(delays, logk_percentiles[0])\n",
    "\n",
    "    ax.fill_between(delays, y_lower, y_upper, alpha=0.3, label='95% CI')\n",
    "    ax.plot(delays, y_median, label='posterior median')\n",
    "    ax.legend()\n",
    "\n",
    "# for linear-in-log-odds model\n",
    "true_params = [pd.DataFrame.from_dict({'β': [0.2], 's': [1], 'α': [2]}),\n",
    "               pd.DataFrame.from_dict({'β': [0.5], 's': [1], 'α': [2]}),\n",
    "               pd.DataFrame.from_dict({'β': [0.8], 's': [1], 'α': [2]})]\n",
    "\n",
    "col_titles = ['example 1', 'example 2', 'example 3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for visualising the various design approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run simulated experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD = lambda: BayesianAdaptiveDesignGeneratorDARC(max_trials=20, \n",
    "                         RA=list(np.arange(5, 99+1, 1)), \n",
    "                         PB=list(np.arange(0.01, 0.99, 20)))\n",
    "\n",
    "design_types = [Griskevicius2011, \n",
    "                DuGreenMyerson2002,\n",
    "                BAD]\n",
    "\n",
    "row_headings = ['Griskevicius\\n et al (2011)',\n",
    "                'Du, Green & Myerson\\n(2002)',\n",
    "                'our approach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(design_types), len(true_params)+1, figsize=(12, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, true_p in enumerate(true_params):\n",
    "    for row, designfunc in enumerate(design_types):\n",
    "        print(f'row, col = ({row},{col})')\n",
    "        design_thing = designfunc()\n",
    "        model = data_generating_model(n_particles=5000)\n",
    "        model.θ_true = pd.DataFrame.from_dict(true_p)\n",
    "        fitted_model, _ = simulated_experiment_trial_loop(design_thing, model)\n",
    "        plot_delay_without_front_end_delays(ax[row,col], design_thing.get_df())\n",
    "        hyperbolic_posterior_predictive(ax[row,col], fitted_model, max_delay[row])\n",
    "        \n",
    "        if col > 0:\n",
    "            ax[row,col].set_ylabel('')\n",
    "        \n",
    "        if row < len(design_types)-1:\n",
    "            ax[row,col].set_xlabel('')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "[ax[r,c].set_xlim([0, 365+7]) for r in range(len(design_types)) for c in range(len(true_params))]\n",
    "[ax[r,c].set_ylim([0, 1]) for r in range(len(design_types)) for c in range(len(true_params))]\n",
    "[ax[0,c].set_title(title) for c, title in enumerate(col_titles)]\n",
    "[ax[r,c].get_legend().remove() for r in range(len(design_types)) for c in range(len(true_params))]\n",
    "\n",
    "pad = 13 # in points\n",
    "for axis, row_title in zip(ax[:,0], row_headings):\n",
    "    axis.annotate(row_title, xy=(0, 0.5), xytext=(-axis.yaxis.labelpad - pad, 0),\n",
    "                  xycoords=axis.yaxis.label, textcoords='offset points',\n",
    "                  size='large', ha='center', va='center', rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for parameter recovery sweeps\n",
    "This will fill in the right hand column with parameter recovery sweeps for the corresponding experiment design approaches (rows). This gives a more high level overview of the resulting posterior over a wide range of $\\log(k)$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7  # 70\n",
    "θsweep = pd.DataFrame.from_dict({'logk': np.linspace(-8, -1, num=N), \n",
    "                                 'α': np.ones(N) * 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_param_name = 'logk'\n",
    "\n",
    "# Griskevicius -----------------------------------------------------------------\n",
    "design_thing = Griskevicius2011()\n",
    "model = data_generating_model(n_particles=5000)\n",
    "θ_estimated_griskevicius, _ = parameter_recovery_sweep(θsweep, model, design_thing, target_param_name)\n",
    "n_trials_griskevicius = 7\n",
    "\n",
    "# Koffarnus & Bickel ----------------------------------------------------------\n",
    "design_thing = Koffarnus_Bickel()\n",
    "model = data_generating_model(n_particles=5000)\n",
    "θ_estimated_koffarnus, _ = parameter_recovery_sweep(θsweep, model, design_thing, target_param_name)\n",
    "n_trials_koffarnus = 5\n",
    "\n",
    "# Du, Green & Myerson ----------------------------------------------------------\n",
    "design_thing = DuGreenMyerson2002()\n",
    "model = data_generating_model(n_particles=5000)\n",
    "θ_estimated_DuGreenMyerson, _ = parameter_recovery_sweep(θsweep, model, design_thing, target_param_name)\n",
    "n_trials_DuGreenMyerson = 6*7\n",
    "\n",
    "# DARC -----------------------------------------------------------------\n",
    "max_trials = 20\n",
    "design_thing = BayesianAdaptiveDesignGeneratorDARC(max_trials=max_trials, \n",
    "                                                   PB=list(np.arange(0.01, 0.99, 20)))\n",
    "model = data_generating_model(n_particles=5000)\n",
    "θ_estimated_darc, _ = parameter_recovery_sweep(θsweep, model, design_thing, target_param_name)\n",
    "n_trials_darc = max_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_errorbar(ax, θsweep, θ_estimated):\n",
    "    err_lower = θ_estimated['logk_median'] - θ_estimated['logk_lower95']\n",
    "    err_upper = θ_estimated['logk_upper95'] - θ_estimated['logk_median']\n",
    "        \n",
    "    ax.plot([-8, -1], [-8, -1], c=[0.7, 0.7, 0.7])\n",
    "    ax.errorbar(x=θsweep['logk'], \n",
    "                y=θ_estimated['logk_median'],\n",
    "                yerr=[err_lower, err_upper],\n",
    "                fmt='o',\n",
    "                c='k', \n",
    "                ms=3)\n",
    "    ax.set_xlabel(r'true $\\log(k)$')\n",
    "    ax.set_ylabel(r'estimated $\\log(k)$')\n",
    "    return\n",
    "\n",
    "col = 3\n",
    "ax[0,col].set_title('Parameter recovery\\nsimulations')\n",
    "# -----------------------------------------------------\n",
    "my_errorbar(ax[0,col], θsweep, θ_estimated_kirby)\n",
    "my_errorbar(ax[1,col], θsweep, θ_estimated_griskevicius)\n",
    "my_errorbar(ax[2,col], θsweep, θ_estimated_koffarnus)\n",
    "my_errorbar(ax[3,col], θsweep, θ_estimated_DuGreenMyerson)\n",
    "my_errorbar(ax[4,col], θsweep, θ_estimated_frye)\n",
    "my_errorbar(ax[5,col], θsweep, θ_estimated_darc)\n",
    "\n",
    "# remove x-labels\n",
    "[ax[i,col].set_xlabel('') for i in range(4)]\n",
    "\n",
    "# move y axis to the right side\n",
    "[ax[i,col].yaxis.tick_right() for i in range(5)]\n",
    "\n",
    "# move y label to the right side\n",
    "[ax[i,col].yaxis.set_label_position(\"right\") for i in range(5)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('risky_choice_demo.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
